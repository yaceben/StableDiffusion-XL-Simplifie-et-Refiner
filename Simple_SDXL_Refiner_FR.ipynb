{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaceben/StableDiffusion-XL-Simplifie-et-Refiner/blob/main/Simple_SDXL_Refiner_FR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Faites-moi tourner en premier! Initialisation de base\n",
        "\n",
        "# @markdown Le code est adapté du notebook https://colab.research.google.com/github/woctezuma/stable-diffusion-colab/blob/main/stable_diffusion.ipynb#scrollTo=AUc4QJfE-uR9\n",
        "%pip install --quiet --upgrade diffusers transformers accelerate invisible_watermark mediapy\n",
        "\n",
        "import mediapy as media\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "from diffusers import DiffusionPipeline, schedulers\n",
        "\n",
        "use_refiner = True\n",
        "\n",
        "scheduler_kwargs = {\n",
        "    \"beta_end\": 0.012,\n",
        "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
        "    \"beta_start\": 0.00085,\n",
        "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
        "    \"num_train_timesteps\": 1000,\n",
        "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
        "    \"steps_offset\": 1,\n",
        "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
        "    \"trained_betas\": None,\n",
        "    \"use_karras_sigmas\": False,\n",
        "}\n",
        "\n",
        "scheduler = schedulers.EulerDiscreteScheduler(**scheduler_kwargs)\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        "    scheduler = scheduler,\n",
        "    )\n",
        "\n",
        "#pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n",
        "\n",
        "if use_refiner:\n",
        "  refiner = DiffusionPipeline.from_pretrained(\n",
        "      \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "      text_encoder_2=pipe.text_encoder_2,\n",
        "      vae=pipe.vae,\n",
        "      torch_dtype=torch.float16,\n",
        "      use_safetensors=True,\n",
        "      variant=\"fp16\",\n",
        "      scheduler = scheduler,\n",
        "  )\n",
        "\n",
        "  #refiner.unet = torch.compile(refiner.unet, mode=\"reduce-overhead\", fullgraph=True)\n",
        "  refiner = refiner.to(\"cuda\")\n",
        "\n",
        "  pipe.enable_model_cpu_offload()\n",
        "else:\n",
        "  pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "bG2hkmSEvByV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prompts (Instructions pour générer l'image)\n",
        "# @\n",
        "prompt = \"a knitted nyan cat, 8k, ultra realistic\" # @param {type:\"string\", allow-input: true}\n",
        "negative_prompt = \"cartoon\" # @param {type:\"string\", allow-input: true}\n",
        "\n",
        "nombre_itérations = 100 # @param {type:\"slider\", min:1, max:1000, step:1}\n",
        "denoising = 0.8 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "force_du_prompt = 7.5 # @param {type: \"number\"}\n",
        "\n",
        "seed = random.randint(0, sys.maxsize)\n",
        "\n",
        "negative_prompt = negative_prompt if negative_prompt != \"\" else None\n",
        "\n",
        "images = pipe(\n",
        "    prompt = prompt,\n",
        "    negative_prompt = negative_prompt,\n",
        "    num_inference_steps = nombre_itérations,\n",
        "    denoising_end = denoising,\n",
        "    guidance_scale = force_du_prompt,\n",
        "    output_type = \"latent\" if use_refiner else \"pil\",\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
        "    ).images\n",
        "\n",
        "if use_refiner:\n",
        "    images = refiner(\n",
        "        prompt = prompt,\n",
        "        negative_prompt = negative_prompt,\n",
        "        num_inference_steps = nombre_itérations,\n",
        "        denoising_start = denoising,\n",
        "        image = images,\n",
        "    ).images\n",
        "\n",
        "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
        "media.show_images(images)\n",
        "images[0].save(\"output.jpg\")"
      ],
      "metadata": {
        "id": "AUc4QJfE-uR9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}